## To use this notebook
1.  Go to ood.ccv.brown.edu (you will need an Oscar account).
2.  Go to 'Clusters' in the blue menu bar at the top and click the drop-down that says '\>\_OSCAR Shell Access'
3.  Go to your home folder and type `git clone https://github.com/compbiocore/intro_scrna_dscov.git`
4.  Look under `Interactive Apps` in the blue menu bar and click on `RStudio on Singularity` under `Expert GUIs`.
Fill in the fields as follows:
-   `Account`: leave blank\
-   `Partition`: leave blank\
-   `Number of hours`: 2\
-   `Num Cores`: 1\
-   `Memory`: 100\
-   `Singularity Container Path` : `/oscar/data/shared/databases/workshops/dscov/intro_scrna_dscov/metadata/intro_scrna_dscov.sif`\
-   `Path for rsession executable`: leave blank\
-   `Package install Path`: leave blank\
-   `R Module`: leave blank\
-   `Additional Data Path`: leave blank\
5.  Once your job starts, click the button to connect to session.\
6.  At the top of the screen you'll see a menu bar that starts with 'file', click on 'file' and 'open file'.\
7.  Go to your home folder where you have cloned this repository and open up `notebooks/Intro.qmd`: \`

## Introduction to scRNA-seq

**What we will cover**\
\* Seurat objects and importing data\
\* Data QC and filtering\
\* SCTransform normalization, clustering, dimension reduction\
\* Data integration\
\* Differential expression\
\* Data visualization\

Much of this notebook is adapted from the Seurat vignettes https://satijalab.org/seurat, GitHub repository https://github.com/satijalab/seurat, and this wiki for comparison of integration methods: https://deepwiki.com/satijalab/seurat

## Seurat objects overview

::: callout-important
In November of 2023, Seurat made a major upgrade to Seurat v5 (https://github.com/satijalab/seurat/releases), which included many new functions and other changes (https://satijalab.org/seurat/articles/announcements.html#changes-in-seurat-v5), including some very big changes to the default behavior of Seurat. **You will likely see different results depending on which version of Seurat you have used for your analysis.** Feel free to come to our office hours if you want help setting up reproducible analyses using either version of Seurat.
:::

This workshop focuses on using Seurat objects to structure your scRNA-seq data (https://github.com/satijalab/seurat/wiki/Seurat), we will attempt to cover how to interact with Seurat objects in Seurat v4 and v5, but won't exhaustively cover the differences between the two versions.

Let's get started. First, we can set the `.libPaths()`, which essentially tells R that it should look for packages inside these locations inside the Singularity container.

```{r message=FALSE}
.libPaths(c('/usr/local/lib/R/site-library', '/usr/local/lib/R/library'))
```

We'll also set a seed at the start of the notebook so that we can reproduce our results if we decide to re-run this notebook at some future date. We also set `future.globals.maxSize`, see the Seurat future vignette linked above for discussion about why we do this (basically we might be exceeding the allowed global variable size so we make that default bigger).

```{r}
set.seed(61)
options(future.globals.maxSize = 4000 * 1024^2)
```

Next, load all the libraries we need, including some Seurat data packages. The last lines will update the Seurat objects so that they are compatible with the newest version of Seurat.

```{r message=FALSE, warning=FALSE}

library(RColorBrewer)
library(Seurat)
library(patchwork)
library(ggplot2)
library(dplyr)
library(hdf5r)
library(stringr)
library(biomaRt)
library(viridis)
library(SeuratDisk)
library(SeuratData)
library(msigdbr)
library(clustree)
library('ifnb.SeuratData')
library('pbmc3k.SeuratData')

data("ifnb")
data("pbmc3k")
ifnb <- UpdateSeuratObject(ifnb)
pbmc3k <- UpdateSeuratObject(pbmc3k)
```

Here's a schematic of a Seurat object:

![Schematic of a Seurat object](image/seurat_object.png){width="470" height="400"}

-   Each Seurat object is composed of different components:
    -   **`assays`** is a list of all the assays in the object.
        -   Defaults to `RNA` assay, but you can add others (like `SCT` for normalized counts, shown in the figure above, could also be antibody-derived tags, etc.).

        -   You can see all assays using `Assays(ifnb)`, see which assay is the currently active assay by looking in the `active.assay` slot (`ifnb@active.assay`) and switch between them using the `DefaultAssay()` function (`DefaultAssay(ifnb) <- 'RNA'`).

        -   Each assay will store multiple transformations of the data in different `slots` (or `layers` in Seurat v5) -- in the case of `RNA` data these slots are:

            -   `@counts` contains the raw counts.
            -   `@data` contains the normalized counts.
            -   `@scale.data` contains the scaled data for dimensional reduction.

        -   The `slots` (Seurat v4) or `layers` (Seurat v5) store the data as a sparse matrix where the rows are gene and the columns are cells.

        -   In Seurat v4, you could access the raw counts like this:`GetAssayData(ifnb, assay='RNA', slot='counts')`. This will still work in Seurat v5, but you'll get a warning message. In Seurat v5 it is intended that you access the counts using the `LayerData` function, like this: `LayerData(ifnb, assay='RNA', layer='counts')`

        -   In either version of Seurat `ifnb[['RNA']]$counts` will also work.
    -   **`meta.data`** is a matrix of all the cell-level metadata.
        -   This will include information about which condition, timepoint, batch, etc. a for a given cell.
        -   It also includes metrics that will be relevant for QC, like `nCount_RNA` and `nFeature_RNA`
            -   `nCount_RNA` is the total number of molecules (UMIs) detected within a cell.
            -   `nFeature_RNA` is the total number of genes detected within a cell.
        -   Once you have completed clustering, you'll also see information about which cluster each cell has been assigned to.
        -   The different categories or columns in the `meta.data` are also called `Idents` in Seurat.
        -   You can see the current `Ident` in the `active.ident` slot (`ifnb@active.ident`) and switch between them using the `Idents()` function (this will probably be important for running differential expression testing).
        -   You can use `table(Idents(ifnb))` for a quick summary of the number of cells in each grouping.
    -   **`graphs`** is a list of the nearest neighbor graphs.
        -   The objects stored in `graphs` are cell x cell matrices containing the neighborhood overlap (Jaccard index) between every cell and its nearest neighbors.
    -   **`reductions`** is a list of `DimReduc` objects.
    -   **`version`** contains information about which version of Seurat was used to make the object.
    -   There are other optional slots, including **`tools`** and **`misc`** that can be populated by specific analysis tools (`tools`) or users can store their own additional information (`misc`).

## Importing data and interacting with Seurat objects

We are using the `SeuratData` package for some test data, which is already installed in this container.

```{r}
SeuratData::AvailableData() %>% data.frame() %>% dplyr::filter(Installed == 'TRUE')
```

It is more likely that you are using Seurat with your own data -- you can use the functions `Read10X` or `Read10X_h5` to import data. `Read10X_h5` works with H5 files -- "Hierarchical Data Format (HDF5 or H5). H5 is a binary format that can compress and access data much more efficiently than text formats such as MEX, which is especially useful when dealing with large datasets." https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/advanced/h5_matrices. You can also use `Read10X` and give a path to a folder that contains your matrix, features, and barcode tsv files. After you have read in the 10X data, use it as the input to the `CreateSeuratObject` function.

We can look at the Seurat object we've loaded from SeuratData:

```{r}
?ifnb
ifnb
```

The `ifnb` dataset is 14,000 IFNB-Stimulated and Control PBMCs (peripheral blood mononuclear cells).

```{r}
?pbmc3k
pbmc3k
```

The `pbmc3k` dataset is 2,700 PBMCs (peripheral blood mononuclear cells).

We can also see that Seurat v5 assays store data in layers. These layers can store raw, un-normalized counts (layer='counts'), normalized data (layer='data') or z-scored/variance-stabilized data (layer='scale.data'). What assays and meta.data are available?

```{r}
ifnb@assays
head(ifnb@meta.data)
```

We have an `RNA` assay, and metadata contains information about which experimental condition the cell came from (`orig.ident` and `stim`), the number of genes (`nFeature_RNA`) and molecules (`nCount_RNA`) in each cell. This particular object also comes pre-annotated (`seurat_annotations`).

If we look at the unique values in `orig.ident`, we see that there's `IMMUNE_CTRL` and `IMMUNE_STIM` samples in one Seurat object.

```{r}
table(ifnb@meta.data$orig.ident)
```

```{r}
pbmc3k@assays
head(pbmc3k@meta.data)
table(pbmc3k@meta.data$orig.ident)

```

If we look at the unique values in `orig.ident` for the `pbmc3k` object, we see that there's only `pbmc3k` samples.

## Data QC

First, lets subset our datasets so they are smaller and easier to work with for this workshop.

```{r}
pbmc3k <- subset(pbmc3k, downsample = 500)
ifnb <- subset(ifnb, downsample = 500)

```

-   For now, let's merge the datasets to make our QC and filtering a bit smoother.
-   `merge()` merges the raw count matrices of two Seurat objects and creates a new Seurat object with the resulting combined raw count matrix.
-   To explicitly specify the original object any particular cell came from, you can set the `add.cell.ids` parameter with an c(x, y) vector, which will prepend the given identifier to the beginning of each cell name.
-   The original project ID will remain stored in object meta data under `orig.ident`.

```{r}
all_data <- merge(x = ifnb, y = pbmc3k, add.cell.ids = c("ifnb", "pbmc3k"), project = 'pbmc')
```

-   We care about the percentage of reads that map to the mitochondrial genome because high mitochondrial reads in a cell can indicate that the cells are low-quality or dying cells
-   The mitochondrial QC metrics are calcualted with the `PercentageFeatureSet()` function, which calculates the percentage of counts originating from a set of features
-   We use the set of all genes starting with MT- as a set of mitochondrial genes -- the format of the mt sequences will vary depending on which organism/genome is used...(might be 'mt-' for example).

```{r}
rownames(all_data) %>% grep(pattern = '^mt-', ignore.case = TRUE, value = TRUE)
```

-   Then add the percent mitochondrial reads to the metadata:

```{r}
all_data[["percent.mt"]] <- PercentageFeatureSet(all_data, pattern = "^MT-")
```

-   Before we plot, we can set the order of the object idents to whatever order we'd like:

```{r}
Idents(all_data) <- 'orig.ident'
levels(all_data) <- c("pbmc3k", "IMMUNE_CTRL", "IMMUNE_STIM")
```

-   We can also look at plots showing the distribution of the `percent.mt`, `nFeature_RNA` and `nCount_RNA`
-   `nFeature_RNA` is the number of genes
-   `nCount_RNA` is the number of UMIs (unique molecules -- like counts)

```{r, warning=FALSE}
VlnPlot(all_data, features = "nFeature_RNA")
```

```{r, warning=FALSE}
VlnPlot(all_data, features = "nCount_RNA")
```

```{r, warning=FALSE}
VlnPlot(all_data, features="percent.mt")
```

```{r, warning=FALSE}
FeatureScatter(all_data, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
```

```{r}
FeatureScatter(all_data, feature1 = "nCount_RNA", feature2 = "percent.mt")
```

```{r}
FeatureScatter(all_data, feature1 = "nFeature_RNA", feature2 = "percent.mt")
```

You can also just use ggplot to make your own custom visualizations of the information in the metadata. We make a separate matrix called `qc_data` and sorting it based on the `percent.mt` column. Then we make our own ggplot and specify that the x and y axes should be `nCount_RNA` and `nFeature_RNA` and that the points should be colored based on `percent.mt`. Then, use `scale_color_gradientn` to specify how the points should be colored, specifying that the limit should be between 0 and 10 and that we should `squish` anything that is out of bounds (effectively making our limits 0 and \>10).

```{r}

qc_data <- all_data@meta.data[c('orig.ident','nCount_RNA','nFeature_RNA','percent.mt')] %>% arrange(percent.mt)

ggplot2::ggplot(qc_data, ggplot2::aes(x = nCount_RNA, y = nFeature_RNA, color = percent.mt)) + 
  ggplot2::geom_point() + 
 ggplot2:: scale_color_gradientn(colors = rev(brewer.pal(5, "Spectral")), limits = c(0,10), oob = (scales::squish)) +
  ggplot2::facet_wrap(~orig.ident) + 
  ggplot2::theme_bw()

```

-   Low quality cells or empty droplets might have very few genes (`nFeatures`)
-   Dead or dying cells will also have high mitochondrial reads (`percent.mt`)
-   Doublets or multiplets will have high gene counts (`nFeatures`)
-   The total number of molecules (`nCount`) detected in a cell corresponds with the number of genes (`nFeatures`)
-   Most of the cells have less than 2000 genes and less than 7000 or so UMIs.
-   Very low mitochondrial counts from the `ifnb` data and the nFeature_RNA scatter plots look strange -- perhaps this dataset was pre-filtered before being packaged into SeuratData.
-   In the `pbmc3k` data, we can see groups of cells with high mitochondrial counts, low UMI counts, and lower numbers of genes.
-   Our goal in QC filtering is to retain as much useful information as we can, while removing doublets, empty droplets, and dead cells.
-   We will pick some thresholds for filtering based off of what we see in our data, keeping in mind that if you are doing this with your own data, your plots will probably look a bit different.

::: callout-important
We don't get into it in this workshop, but an additional QC consideration is ambient RNA. Look at this document from 10x for more information: https://www.10xgenomics.com/analysis-guides/introduction-to-ambient-rna-correction
:::

## Data Filtering

-   Let's filter our data using `subset`, we'll keep cells that have between 500 and 7000 nFeature_RNA (genes) and less than 5% mitochondrial reads.

```{r}
all_data_sub <- subset(all_data, subset = nFeature_RNA > 500 & nFeature_RNA < 7000 & percent.mt < 5)
```

-   You can re-examine your QC plots after filtering if you'd like:

```{r}
qc_data_sub <- all_data_sub@meta.data[c('orig.ident','nCount_RNA','nFeature_RNA','percent.mt')] %>% arrange(percent.mt)

ggplot2::ggplot(qc_data_sub,ggplot2:: aes(x = nCount_RNA, y = nFeature_RNA, color = percent.mt)) + 
  ggplot2::geom_point() + 
  ggplot2::scale_color_gradientn(colors = rev(brewer.pal(5, "Spectral")), limits = c(0,10), oob = (scales::squish)) +
  ggplot2::facet_wrap(~orig.ident) + 
  ggplot2::theme_bw()
```

-   We can also take a look at how many cells we lost from filtering:

```{r}
table(all_data@meta.data$orig.ident)
table(all_data_sub@meta.data$orig.ident)

```

## Normalization

### Theory

scRNAseq data is normalized so that we can mitigate technical effects while preserving the biological signal in the data -- we should be able to find the biological signal in cells irrespective of how deeply we sequenced the cell. The theory behind SCTransform (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1) is very similar to the generalized linear models (GLMs) used in bulk RNAseq analysis packages like DESeq2 and edgeR. In DESeq2 a negative binomial model is fitted to the counts and the mean and dispersion (roughly speaking how variable the observed count will be from the mean count) estimates from that model are used as the test statistics for comparison between group and the same idea applies with SCTransform. SCTransform also pools information across genes with similar abundances in order to address the higher sparsity of single cell data.

Below is a side-by-side comparison of sctransform with NormalizeData, FindVariableFeatures and ScaleData on the PBMC3k data:

![sct](image/sctransform_vs_regular.png)

We also like this figure from the SCTransform paper, which shows how SCTransform ('Pearson Residuals') and the standard log-transformation approach ('Log-normalization') helps alleviate variance in your data from sequencing depth alone :

![sct_fig6](image/sct_fig6.png)

### When should you not use SCTransform?

The paper states:

`As our workflow leverages all genes (or a random subset) for the initial regularization, we make an implicit assumption that the majority of genes in the dataset do not exhibit significant biological variation...this assumption may be overly simplistic when performing scRNA-seq on a highly heterogeneous sample, we did not observe adverse affects when applying our model to human PBMC data, or any of the other datasets we examined.`

SCTransform might not work well if your data is highly heterogeneous and you expect that a high proportion of genes will exhibit significant biological variation across your samples. In this case, we would recommend the more standard workflow of `NormalizeData`, `FindVariableFeatures`, and `ScaleData`.

### SCTransform versions

Seurat v5 runs SCTransform v2 (https://satijalab.org/seurat/archive/v4.3/sctransform_v2_vignette) by default, while Seurat v4 runs SCTransform v1 by default. SCTransform v2 "improves speed and memory consumption, the stability of parameter estimates, the identification of variable features, and the the ability to perform downstream differential expression analyses." This means you might get different results if you run Seurat v5 and re-normalize data that you have previously processed with Seurat v4. If you want to change from the default veresion of SCTransform, you can add the argument `vst.flavor = "v1"` (or `vst.flavor = "v2"`))

### Running SCTransform

We will normalize using SCTransform and you might get see a warning that says 'iteration limit reached' when you run the function. This warning can be ignored (https://github.com/satijalab/sctransform/issues/25) because the parameter estimation generating this warning is regularized later anyway. You can use the `vars.to.regress` argument to regress out nuisance variables (like cell cycle, batch effects, or `percent.mt`). By default SCTransform will only return data for variable genes in the scale data slot -- adding the `return.only.var.genes = FALSE` argument to the function call to turn this option off (https://github.com/satijalab/seurat/issues/3553). In previous versions of Seurat, you would have to split your object into a list of Seurat objects based on the `orig.ident` and then run `SCTransform` on the list, which is not necessary in Seurat v5 -- but we do have to split the layers by their `orig.ident`:

```{r}
all_data_sub[["RNA"]] <- split(all_data_sub[["RNA"]], f = all_data_sub$orig.ident)
```

```{r, warning=FALSE}

start.time <- Sys.time()
all_data_sub <- SCTransform(all_data_sub, vars.to.regress = "percent.mt", verbose = FALSE)
end.time <- Sys.time()
end.time - start.time
  
```

Then run PCA

```{r, warning=FALSE}
all_data_sub <- RunPCA(all_data_sub)
```

We can make an elbow plot:

```{r}
ElbowPlot(all_data_sub)
```

Based on this plot, we get diminishing information returned once we get above \~10-15 PCs. We will use this information when we run clustering.

## Integration

Integration of single-cell sequencing datasets, for example across experimental batches, donors, or conditions, is often an important step in scRNA-seq workflows. Integrative analysis can help to match shared cell types and states across datasets, which can boost statistical power, and most importantly, facilitate accurate comparative analysis across datasets.

While the goal of matching shared cell types across datasets may be important for many problems, users may also be concerned about which method to use, or that integration could result in a loss of biological resolution. In Seurat v5, we introduce more flexible and streamlined infrastructure to run different integration algorithms with a single line of code. This makes it easier to explore the results of different integration methods, and to compare these results to a workflow that excludes integration steps.

Seurat v5 enables streamlined integrative analysis using the `IntegrateLayers` function. The method currently supports four integration methods by default. Each of these methods performs integration in low-dimensional space, and returns a dimensional reduction (i.e. integrated.rpca) that aims to co-embed shared cell types across batches (samples). These integration methods can be divided into two categories:

Anchor-based methods: CCA, RPCA, and JointPCA, which rely on identifying pairs of cells (anchors) that are mutual nearest neighbors between datasets

Non-anchor-based methods: Harmony, which uses soft clustering and iterative correction

-   CCA integration (method=CCAIntegration)
-   RPCA integration (method=RPCAIntegration)
-   Joint PCA integration (method=JointPCAIntegration)
-   Harmony (method=HarmonyIntegration)

### Canonical Correlation Analysis (CCA) Integration

CCA (Canonical Correlation Analysis) Integration was the first integration method developed for Seurat. It identifies common sources of variation between datasets by finding linear combinations of features with maximum correlation.

-   CCA integration:

    -   Performs canonical correlation analysis between pairs of datasets
    -   L2-normalizes the cell embeddings to focus on correlation strength rather than magnitude
    -   Identifies mutual nearest neighbors (anchors) between datasets in the CCA space
    -   Uses these anchors to correct the data and align matching cell populations

By identifying shared sources of variation between datasets, CCA is well-suited for identifying anchors when cell types are conserved, but there are very substantial differences in gene expression across experiments. CCA-based integration therefore enables integrative analysis when experimental conditions or disease states introduce very strong expression shifts, or when integrating datasets across modalities and species. However, CCA-based integration may also lead to overcorrection, especially when a large proportion of cells are non-overlapping across datasets.

### Reciprocal Principal Components Analysis (RPCA) Integration

RPCA (Reciprocal PCA) Integration uses principal component analysis for integration. Unlike CCA, which finds correlations between datasets, RPCA projects each dataset onto the other's PCA space.

-   RPCA integration:

    -   Computes PCA on each dataset separately
    -   Projects each dataset onto the other's PCA space (reciprocal projection)
    -   L2-normalizes the cell embeddings
    -   Identifies mutual nearest neighbors (anchors) between datasets in the projected space
    -   Uses these anchors to correct the data and align matching cell populations

We recommend RPCA during integrative analysis where: A substantial fraction of cells in one dataset have no matching type in the other, datasets that originate from the same platform (i.e. multiple lanes of 10x genomics), or if there are a large number of datasets or cells to integrate.

### JointPCA Integration

JointPCA (Joint PCA) Integration first combines all datasets and then performs PCA on the combined data. This method is simpler but can be effective when datasets are already somewhat aligned or have minor batch effects.

-   JointPCA integration:

    -   Merges the datasets into a single matrix
    -   Performs PCA on the combined data
    -   L2-normalizes the cell embeddings
    -   Identifies mutual nearest neighbors (anchors) between original datasets in the joint PCA space
    -   Uses these anchors to correct the data and align matching cell populations

JointPCA is often faster than CCA or RPCA but may be less effective for datasets with substantial differences or batch effects.

### Harmony Integration

Harmony Integration is a different approach developed by the Korsunsky et al. team (https://doi.org/10.1038/s41592-019-0619-0). Instead of using an anchor-based approach, Harmony uses soft clustering and iterative correction to align datasets.

-   Harmony integration:

    -   Performs PCA on the combined datasets
    -   Applies soft clustering to group cells by similarity
    -   Iteratively corrects cluster assignments and cell embeddings to align datasets
    -   Uses ridge regression to minimize the effect of dataset-specific variation

Harmony is generally faster than anchor-based methods and often performs well on datasets with complex batch effects.

We will run `CCAIntegration` (this was the default flavor of integration in previous versions of Seurat), `JointPCAIntegration`, `HarmonyIntegration`, and `RPCAIntegration`. Note that we are specifying that we used `SCT` normalization:

```{r}
start.time <- Sys.time()
all_data_sub<- IntegrateLayers(
  object = all_data_sub, method = CCAIntegration,
  orig.reduction = "pca", new.reduction = "integrated.cca", normalization.method = "SCT",
  verbose = FALSE
)
end.time <- Sys.time()
end.time - start.time
```

```{r}
start.time <- Sys.time()
all_data_sub <- IntegrateLayers(
  object = all_data_sub, method = JointPCAIntegration,
  orig.reduction = "pca", new.reduction = "integrated.jpca", normalization.method = "SCT",
  verbose = FALSE
)
end.time <- Sys.time()
end.time - start.time
```

```{r}
start.time <- Sys.time()
all_data_sub <- IntegrateLayers(
  object = all_data_sub, method = HarmonyIntegration,
  orig.reduction = "pca", new.reduction = "harmony", normalization.method = "SCT",
  verbose = FALSE
)
end.time <- Sys.time()
end.time - start.time
```

```{r}
start.time <- Sys.time()
all_data_sub <- IntegrateLayers(
  object = all_data_sub, method = RPCAIntegration,
  orig.reduction = "pca", new.reduction = "integrated.rpca", normalization.method = "SCT",
  verbose = FALSE
)
end.time <- Sys.time()
end.time - start.time
```

## Clustering

Seurat will cluster your cells into groups of cells with similar expression patterns. The first step is `FindNeighbors`, which will construct a K-nearest neighbor (KNN) graph based on the euclidean distance in PCA space, and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). To cluster the cells, we run `FindClusters` to apply the Louvain algorithm to iteratively group cells together, with the goal of optimizing the standard modularity function. `FindClusters` takes a `resolution` argument (defaults to a value of 0.8), which sets the granularity of the clustering, setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells but the resolution might increase for larger datasets. Use a value above 1 if you want a larger number of communities (clusters), and a value below 1 if you want a smaller number of communities.

```{r}

all_data_sub <- FindNeighbors(all_data_sub, dims = 1:10, reduction = "pca")
all_data_sub <- FindClusters(all_data_sub, resolution = .6, cluster.name = "unintegrated_clusters")

all_data_sub <- FindNeighbors(all_data_sub, reduction = "integrated.cca", dims = 1:10)
all_data_sub <- FindClusters(all_data_sub, resolution = .6, cluster.name = "cca_clusters")

all_data_sub <- FindNeighbors(all_data_sub, reduction = "integrated.jpca", dims = 1:10)
all_data_sub <- FindClusters(all_data_sub, resolution = .6, cluster.name = "jpca_clusters")

all_data_sub <- FindNeighbors(all_data_sub, reduction = "harmony", dims = 1:10)
all_data_sub <- FindClusters(all_data_sub, resolution = .6, cluster.name = "harmony_clusters")

all_data_sub <- FindNeighbors(all_data_sub, reduction = "integrated.rpca", dims = 1:10)
all_data_sub <- FindClusters(all_data_sub, resolution = .6, cluster.name = "rpca_clusters")
```

Run UMAP (Uniform Manifold Approximation and Projection) dimensional reduction technique on the unintegrated data and the different integration methods:

```{r}
all_data_sub <- RunUMAP(all_data_sub, reduction = "pca", dims = 1:10, reduction.name = "umap.unintegrated")
all_data_sub <- RunUMAP(all_data_sub, reduction = "integrated.cca", dims = 1:10, reduction.name = "umap.cca")
all_data_sub <- RunUMAP(all_data_sub, reduction = "integrated.jpca", dims = 1:10, reduction.name = "umap.jpca")
all_data_sub <- RunUMAP(all_data_sub, reduction = "harmony", dims = 1:10, reduction.name = "umap.harmony")
all_data_sub <- RunUMAP(all_data_sub, reduction = "integrated.rpca", dims = 1:10, reduction.name = "umap.rpca")

```

```{r}
p1 <- DimPlot(
  all_data_sub,
  reduction = "umap.unintegrated",
  group.by = "orig.ident",  
  label.size = 2,
  pt.size = .5,
  alpha = .25
)

p2 <- DimPlot(
  all_data_sub,
  reduction = "umap.cca",
  group.by = "orig.ident",  
  label.size = 2,
  pt.size = .5,
  alpha = .25
)


p3 <- DimPlot(
  all_data_sub,
  reduction = "umap.jpca",
  group.by = "orig.ident",  
  label.size = 2,
  pt.size = .5,
  alpha = .25
)

p4 <- DimPlot(
  all_data_sub,
  reduction = "umap.harmony",
  group.by = "orig.ident",  
  label.size = 2,
  pt.size = .5,
  alpha = .25
)


p5 <- DimPlot(
  all_data_sub,
  reduction = "umap.rpca",
  group.by = "orig.ident",  
  label.size = 2,
  pt.size = .5,
  alpha = .25
)

```

Patchwork to view the plots together

```{r}
 p1+p2+p3+p4+p5+plot_layout(ncol = 3, guides = "collect")
```

Once integrative analysis is complete, you can rejoin the layers - which collapses the individual datasets together and recreates the original counts and data layers. You will need to do this before performing any differential expression analysis. However, you can always re-split the layers in case you would like to re-perform integrative analysis.

```{r}
all_data_sub <- JoinLayers(all_data_sub, assay ='RNA')
```

We can also see how well the pre-populated cell annotations and Seurat clusters agree, with a table where the rpca_clusters are rows and cell annotations are rows:

```{r}
table(all_data_sub$seurat_annotations, all_data_sub$rpca_clusters)
```

We can also compare dimplots with different labels:
```{r}
Idents(all_data_sub) <- 'seurat_annotations'
plot1 <- DimPlot(all_data_sub) 
LabelClusters(plot1, id = "ident", box= TRUE, size = 5, repel = T, fill = 'white')

Idents(all_data_sub) <- 'rpca_clusters'
plot2 <- DimPlot(all_data_sub) 
LabelClusters(plot2, id = "ident", box= TRUE, size = 5, repel = T, fill = 'white')

plot1 + plot2

```


### Clustering resolution selection

You can use the `clustree` package to get a sense of how the resolution to select will impact the clustering.

First, try running the clustering across a range of resolutions:

```{r message=FALSE, warning=FALSE, output=FALSE}
resolution.range <- seq(from = 0, to = 1.2, by = 0.1)
tree <- FindClusters(all_data_sub, resolution = resolution.range)


```

Then we can look at the clustering tree.

```{r}
clustree(tree)
```

The size of the dots indicates how many cells are in each cluster and the color indicates the resolution used. At the top is showing us the clustering results from `resolution = 0`, and moving down the tree we can see clusters splitting out into smaller sub-clusters as we reach higher resolutions. If you see situations where clusters split and then re-cluster, this might be a sign that you are getting into over-clustering territory.



## Differential Expression Analysis

The bulk of Seuratâ€™s differential expression features can be accessed through the `FindMarkers()` or `FindAllMarkers()` functions. By default, Seurat performs differential expression (DE) testing based on the non-parametric Wilcoxon rank sum test. To test for DE genes between two specific groups of cells, use `FindMarkers()` and specify the `ident.1` and `ident.2` parameters. Use `FindAllMarkers()` to test each `ident` to all other idents. If you have a more complex experimental design, Seurat might not be the best choice and you can come visit us at office hours to discuss your options.

Since we normalized using SCTransform, we have to run `PrepSCTFindMarkers()` first. Given a merged object with multiple SCT models, this function uses minimum of the median UMI (calculated using the raw UMI counts) of individual objects to reverse the individual SCT regression model using minimum of median UMI as the sequencing depth covariate. The counts slot of the SCT assay is replaced with recorrected counts and the data slot is replaced with log1p of recorrected counts. Then set the `DefaultAssay` to be the RNA assay.

```{r}
Idents(all_data_sub) <- "orig.ident"
all_data_sub <- PrepSCTFindMarkers(all_data_sub)
DefaultAssay(all_data_sub) <- "RNA"

stim_vs_ctrl <- FindMarkers(all_data_sub, ident.1 = "IMMUNE_STIM", ident.2 = "IMMUNE_CTRL")
head(stim_vs_ctrl %>% dplyr::filter(p_val_adj < .05 & avg_log2FC > 1))
```

The results data frame has the following columns :

```         
p_val : p-value (unadjusted)
avg_log2FC : log fold-change of the average expression between the two groups. Positive values indicate that the feature is more highly expressed in the first group.
pct.1 : The percentage of cells where the feature is detected in the first group
pct.2 : The percentage of cells where the feature is detected in the second group
p_val_adj : Adjusted p-value, based on Bonferroni correction using all features in the dataset.
```

If the `ident.2` argument is omitted, `FindMarkers` will test for differentially expressed features between the group specified by `ident.1` and all other cells. Additionally, the parameter `only.pos` can be set to TRUE to only search for positive markers, i.e. features that are more highly expressed in the ident.1 group.

```{r}
stim_vs_all <- FindMarkers(all_data_sub, ident.1 = "IMMUNE_STIM", only.pos = T)
head(stim_vs_all %>% dplyr::filter(p_val_adj < .05 & avg_log2FC > 1))
```

We can switch idents to find marker genes for the clusters:

```{r}
Idents(all_data_sub) <- 'rpca_clusters'
```

Use `FindAllMarkers` to compare each cluster to all the other clusters. For the sake of speed, we are selecting only positive genes that are expressed in at least 90% of the cells for a given cluster:

```{r}
rpca_markers <- FindAllMarkers(all_data_sub, min.pct = .90, only.pos=TRUE)
```

Look at the marker genes with the biggest fold change per cluster

```{r}
top_cluster_markers <- 
  rpca_markers %>% 
  group_by(cluster) %>%
  dplyr::filter(p_val_adj <= 1e-100) %>%
  dplyr::filter(avg_log2FC > 1) %>% 
  dplyr::filter(pct.1 > .9) %>%
  slice_max(n = 2, order_by = abs(avg_log2FC))
top_cluster_markers
```

Make a `FeaturePlot` to look at the expression of specific genes. It will plot the `data` slot from the default assay. We can switch the default assay to SCT first and specify that we want to use the `data` slot (log1p(counts)):

```{r}
DefaultAssay(all_data_sub) <- "SCT"

FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.rpca', order = T, slot = 'data')
```

We can adjust the default colors and use one of the `viridis` palettes:

```{r}
FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.rpca', order = T, slot = 'data') & ggplot2::scale_color_gradientn(colors = viridis::turbo(n = 10, direction = 1))

```

We can add the cluster labels:

```{r}
FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.rpca', order = T, slot = 'data', label = TRUE, repel = TRUE) & ggplot2::scale_color_gradientn(colors = viridis::turbo(n = 10, direction = 1))

```

The labels are a bit hard to see. We can use `RColorBrewer` palettes instead and specify that we want to drop the colors on the extreme ends of the `Spectral` palette:

```{r}
FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.rpca', order = T, slot = 'data', label = TRUE, repel = TRUE) & ggplot2::scale_color_gradientn(colors = rev(brewer.pal(10, 'Spectral'))[3:8])
```

And add a legend title

```{r}
FeaturePlot(all_data_sub, features = c("CCL3"), reduction = 'umap.rpca', order = T, slot = 'data', label = TRUE, repel = TRUE) & ggplot2::scale_color_gradientn(colors = rev(brewer.pal(10, 'Spectral'))[3:8]) & ggplot2::labs(color = "log1p\n(counts)")
```

We can also make a heatmap of the cluster markers. Seurat heatmaps use the `scale.data` slot by default.

```{r}
DoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene)
```

We can customize this heatmap as well:

```{r}
DoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene) & viridis::scale_fill_viridis() 
```

We can adjust which legends are shown, like this:

```{r}
DoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene) & viridis::scale_fill_viridis() & ggplot2::guides(fill=FALSE)
```

Or like this:

```{r}
DoHeatmap(subset(all_data_sub, downsample = 50), features = top_cluster_markers$gene) & viridis::scale_fill_viridis() & ggplot2::guides(colour=FALSE)
```

Another helpful visualization from Seurat is `DotPlot`. The size of each dot indicates the percentage of cells expressing the feature and the color is the average expression level. It uses the scale.data slot by default.

```{r}
DotPlot(all_data_sub, features = top_cluster_markers$gene) 
```

We can use more custom colors:

```{r}
DotPlot(all_data_sub, features = top_cluster_markers$gene) & 
    viridis::scale_color_viridis(option = "magma", direction = -1) 
```

## Conclusion

Thanks for joining! If you have questions, you can stop by our Zoom office hours. For more information, consult the CCV calendar: https://events.brown.edu/ccv/all
